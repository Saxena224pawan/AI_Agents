
# 2024 Video Generation Papers Summary

1. **DrivingGPT**  
   - **Authors**: Yuntao Chen, Yuqi Wang, Zhaoxiang Zhang  
   - **Core Components**: A multimodal driving language utilizing interleaved image and action tokens.  
   - **Novel Techniques**: Unifies driving world modeling and trajectory planning into a single sequence modeling problem; demonstrates strong performance in action-conditioned video generation.

2. **ZeroHSI**  
   - **Authors**: Hongjie Li, Hong-Xing Yu, Jiaman Li, Jiajun Wu  
   - **Core Components**: Integrates video generation and neural human rendering for human-scene interaction synthesis.  
   - **Novel Techniques**: Enables zero-shot 4D HSI synthesis using motion priors from video generation models, eliminating the need for ground-truth motion data.

3. **DiTCtrl**  
   - **Authors**: Minghong Cai, et al.  
   - **Core Components**: MM-DiT architecture for video generation.  
   - **Novel Techniques**: A training-free multi-prompt video generation approach that emphasizes temporal video editing, achieving smoother transitions without additional training.

4. **ClassifyViStA**  
   - **Authors**: S. Balasubramanian, et al.  
   - **Core Components**: An AI-based framework for classifying gastrointestinal bleeding in wireless capsule endoscopy videos.  
   - **Novel Techniques**: Combines classification with attention and segmentation branches to enhance interpretability and diagnosis efficiency.

5. **3DEnhancer**  
   - **Authors**: Yihang Luo, et al.  
   - **Core Components**: A multi-view latent diffusion model for 3D enhancement.  
   - **Novel Techniques**: Introduces a pose-aware encoder and a multi-view attention module to maintain consistency across viewing angles.

6. **Explainable Multi-Modal Data Exploration**  
   - **Authors**: Farhad Nooralahzadeh, et al.  
   - **Core Components**: A system for exploring multi-modal data using natural language.  
   - **Novel Techniques**: Leverages a LLM-based agent for effective querying of multi-modal databases, enhancing performance metrics such as accuracy and latency.

7. **RDPM**  
   - **Authors**: Wu Xiaoping, Hu Jie, Wei Xiaoming  
   - **Core Components**: Recurrent Diffusion Probabilistic Model (RDPM).  
   - **Novel Techniques**: Enhances diffusion processes with recurrent token prediction, facilitating new approaches in discrete diffusion modeling.

8. **The Value of AI-Generated Metadata for UGC Platforms**  
   - **Authors**: Xinyi Zhang, et al.  
   - **Core Components**: Study on the impact of AI-generated metadata on user-generated content platforms.  
   - **Novel Techniques**: Examines improvements in viewership metrics when AI-generated titles are utilized, showcasing benefits of human-AI co-creation.

9. **Quo Vadis, Anomaly Detection?**  
   - **Authors**: Xi Ding, Lei Wang  
   - **Core Components**: Review of advancements in video anomaly detection using LLM and VLM integration.  
   - **Novel Techniques**: Focuses on enhancing interpretability, temporal reasoning, and adapting to few-shot detection scenarios.

10. **Smooth-Foley**  
    - **Authors**: Yaoyun Zhang, et al.  
    - **Core Components**: Video-to-audio generative model for Foley sound creation.  
    - **Novel Techniques**: Utilizes semantic guidance for improved audio-video alignment and temporal correctness in generated sounds.
