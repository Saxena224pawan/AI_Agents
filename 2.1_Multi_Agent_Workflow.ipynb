{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (0.6.0)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: asyncer>=0.0.8 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: flaml in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (2.3.3)\n",
      "Requirement already satisfied: openai>=1.57 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (1.58.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (24.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (2.10.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (0.8.0)\n",
      "Requirement already satisfied: websockets<15,>=14 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (14.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pyautogen) (1.26.4)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=0.20.0 (from librosa)\n",
      "  Downloading scikit_learn-1.6.0-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting joblib>=0.14 (from librosa)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp39-cp39-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp39-cp39-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from asyncer>=0.0.8->pyautogen) (4.7.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai>=1.57->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai>=1.57->pyautogen) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai>=1.57->pyautogen) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai>=1.57->pyautogen) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai>=1.57->pyautogen) (4.67.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.27.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.20.0->librosa)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa)\n",
      "  Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from docker->pyautogen) (307)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from docker->pyautogen) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from tiktoken->pyautogen) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio<5.0,>=3.4.0->asyncer>=0.0.8->pyautogen) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio<5.0,>=3.4.0->asyncer>=0.0.8->pyautogen) (3.10)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: certifi in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.57->pyautogen) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.57->pyautogen) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.57->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from tqdm>4->openai>=1.57->pyautogen) (0.4.6)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp39-cp39-win_amd64.whl (74 kB)\n",
      "Downloading numba-0.60.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 11.1 MB/s eta 0:00:00\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_learn-1.6.0-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.1 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 12.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.9/46.2 MB 14.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.2/46.2 MB 12.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.9/46.2 MB 12.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.7/46.2 MB 12.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.8/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.2/46.2 MB 11.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.8/46.2 MB 11.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 12.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.6/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.5/46.2 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.8/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 31.2/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.6/46.2 MB 12.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.2/46.2 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.5/46.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.4/46.2 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/46.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 11.8 MB/s eta 0:00:00\n",
      "Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Downloading soxr-0.5.0.post1-cp39-cp39-win_amd64.whl (167 kB)\n",
      "Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Downloading llvmlite-0.43.0-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.7/28.1 MB 11.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.8/28.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.7/28.1 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.3/28.1 MB 10.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.2/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.7/28.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 22.3/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.8/28.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: threadpoolctl, soxr, scipy, pycparser, msgpack, llvmlite, lazy-loader, joblib, audioread, scikit-learn, pooch, numba, cffi, soundfile, librosa\n",
      "Successfully installed audioread-3.0.1 cffi-1.17.1 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 pycparser-2.22 scikit-learn-1.6.0 scipy-1.13.1 soundfile-0.12.1 soxr-0.5.0.post1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pyautogen librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "def load_api_key(yml_file):\n",
    "    with open(yml_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)  # Safely load the YAML file\n",
    "        return config.get('openai_key')  # Retrieve the 'api_key'\n",
    "\n",
    "# Usage\n",
    "os.environ['OPENAI_API_KEY'] =load_api_key('chatgpt_api_credentials.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import config_list_from_json\n",
    "from autogen import UserProxyAgent, AssistantAgent, GroupChat, GroupChatManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [{\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"api_key\": os.environ['OPENAI_API_KEY']\n",
    "}\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_config ={\n",
    "    \"cache_seed\": 42, #change the cache seed for different trials\n",
    "    \"temperature\":0,\n",
    "    \"config_list\": configs,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"A human admin. Interact with a planner to discuss the plan of execution. The plan needs to be approved by this admin.\",\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message='Planner. Suggest a plan. Revise the plan based on feedback froma critic agent.\\\n",
    "          The plan may involve an engineer who can write code and a scientist who doesnt write code.\\\n",
    "            Explain the plan first, Be clear which step is performed by engineer and which i performed by scientist'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer = AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=gpt4o_config,\n",
    "    system_message=\"\"\"Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientist = AssistantAgent(\n",
    "    name=\"Scientist\",\n",
    "    llm_config=gpt4o_config,\n",
    "    system_message=\"\"\"Scientist. You follow an approved plan.\n",
    "    You are able to categorize papers after seeing their abstracts printed.\n",
    "    You don't write code.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"\"\"Planner. Suggest a plan. Revise the plan based on feedback\n",
    "    from admin and critic, until admin approval. The plan may involve an engineer\n",
    "    who can write code and a scientist who doesn't write code. Explain the plan \n",
    "    first. Be clear which step is performed by an engineer, and which step is \n",
    "    performed by a scientist.\n",
    "    \"\"\",\n",
    "    llm_config=gpt4o_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "work_dir = Path('video_papers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer\\\n",
    "        and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"last_n_messages\": 3,\n",
    "                           \"work_dir\": work_dir, \"use_docker\":False},\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = AssistantAgent(\n",
    "    name=\"Critic\", \n",
    "    system_message=\"\"\"Critic. Double check plan, claims, code from other\n",
    "    agents and provide feedback. Check whether the plan includes adding \n",
    "    verifiable info such as source URL.\n",
    "    \"\"\",\n",
    "    llm_config=gpt4o_config,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = GroupChat(\n",
    "    agents=[user_proxy, engineer, scientist, planner, executor, critic], \n",
    "    messages=[], max_round=20\n",
    ")\n",
    "manager = GroupChatManager(groupchat=groupchat, \n",
    "                           llm_config=gpt4o_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "Find various state of the art video generation paper architectures. Create markdown table summarizing these architectures named video_paper.md as well as markdown for each of the architecture saved as architecture_name.md and python code for each architectures as architecture.py.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Planner\n",
      "\u001b[0m\n",
      "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
      "\n",
      "### Plan for Video Generation Paper Architectures\n",
      "\n",
      "The goal of this plan is to gather state-of-the-art video generation architectures from recent research papers, summarize them in a markdown table, and create individual markdown files and Python code files for each architecture. \n",
      "\n",
      "#### Steps Involved:\n",
      "\n",
      "1. **Research and Data Collection (Scientist)**\n",
      "   - The scientist will conduct a literature review to identify and collect state-of-the-art video generation architectures from recent research papers. This will involve searching through academic databases, reading abstracts, and selecting relevant papers.\n",
      "\n",
      "2. **Summarization (Scientist)**\n",
      "   - The scientist will summarize the key features of each architecture, including the model name, authors, year of publication, and a brief description of the approach. This information will be compiled into a markdown table format.\n",
      "\n",
      "3. **Markdown Table Creation (Engineer)**\n",
      "   - The engineer will create a markdown file named `video_paper.md` that contains the summarized table of architectures.\n",
      "\n",
      "4. **Individual Architecture Files (Engineer)**\n",
      "   - For each architecture identified, the engineer will create a separate markdown file named `architecture_name.md` (where `architecture_name` is the name of the architecture) that includes a detailed description, key features, and any relevant diagrams or figures.\n",
      "\n",
      "5. **Python Code Implementation (Engineer)**\n",
      "   - The engineer will write Python code for each architecture and save it in a file named `architecture.py`. This code will implement the core functionality of the architecture as described in the respective research papers.\n",
      "\n",
      "6. **Review and Feedback (Admin)**\n",
      "   - The admin will review the markdown files and Python code, providing feedback for any necessary revisions.\n",
      "\n",
      "7. **Revisions (Scientist and Engineer)**\n",
      "   - Based on the admin's feedback, the scientist and engineer will make the necessary revisions to the markdown files and code.\n",
      "\n",
      "8. **Final Approval (Admin)**\n",
      "   - Once all revisions are made, the admin will give final approval for the project.\n",
      "\n",
      "### Summary of Responsibilities:\n",
      "- **Scientist**: Research and data collection, summarization of architectures.\n",
      "- **Engineer**: Creation of markdown files, implementation of Python code.\n",
      "\n",
      "### Next Steps:\n",
      "- The scientist will begin the research phase to identify relevant papers. \n",
      "- The engineer will prepare the markdown file templates for the architectures.\n",
      "\n",
      "Please provide feedback or any additional requirements for this plan.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "The plan looks comprehensive and well-structured. Here are a few suggestions and considerations to enhance the process:\n",
      "\n",
      "1. **Define Criteria for \"State-of-the-Art\"**: It might be helpful to establish specific criteria for what qualifies as \"state-of-the-art\" in video generation. This could include metrics like performance benchmarks, novelty of approach, or citation counts.\n",
      "\n",
      "2. **Collaboration Tools**: Consider using collaborative tools (like Google Docs or Overleaf) for the initial research and summarization phase to allow for real-time input and feedback.\n",
      "\n",
      "3. **Version Control**: Implement a version control system (like Git) for managing the markdown files and Python code. This will help track changes and facilitate collaboration.\n",
      "\n",
      "4. **Include References**: Ensure that each architecture's markdown file includes proper citations and links to the original papers for further reading.\n",
      "\n",
      "5. **Testing the Code**: After the Python code is written, it would be beneficial to include a testing phase to ensure that the implementations work as intended.\n",
      "\n",
      "6. **Visual Aids**: If possible, include visual aids (like diagrams or flowcharts) in the architecture markdown files to enhance understanding.\n",
      "\n",
      "7. **Feedback Loop**: Establish a clear feedback loop after the initial drafts are created, allowing for iterative improvements based on input from the admin and other stakeholders.\n",
      "\n",
      "8. **Timeline**: Consider setting a timeline for each phase of the project to ensure timely completion.\n",
      "\n",
      "Once the scientist begins the research phase, it would be good to have regular check-ins to monitor progress and address any challenges that arise. \n",
      "\n",
      "Please let me know if you would like to proceed with this plan or if there are any adjustments you would like to make!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Engineer\n",
      "\u001b[0m\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "The suggestions provided by the scientist are valuable and will enhance the overall process of gathering and summarizing state-of-the-art video generation architectures. Here’s an updated plan incorporating the feedback:\n",
      "\n",
      "### Updated Plan for Video Generation Paper Architectures\n",
      "\n",
      "#### Steps Involved:\n",
      "\n",
      "1. **Define Criteria for \"State-of-the-Art\"**:\n",
      "   - Establish specific criteria for selection, such as performance benchmarks, novelty, and citation counts.\n",
      "\n",
      "2. **Research and Data Collection (Scientist)**:\n",
      "   - Conduct a literature review to identify relevant papers based on the defined criteria.\n",
      "\n",
      "3. **Collaborative Tools**:\n",
      "   - Use collaborative tools (e.g., Google Docs or Overleaf) for real-time input during the research and summarization phase.\n",
      "\n",
      "4. **Summarization (Scientist)**:\n",
      "   - Summarize key features of each architecture, including model name, authors, year, and a brief description.\n",
      "\n",
      "5. **Markdown Table Creation (Engineer)**:\n",
      "   - Create a markdown file named `video_paper.md` containing the summarized table of architectures.\n",
      "\n",
      "6. **Individual Architecture Files (Engineer)**:\n",
      "   - For each architecture, create a markdown file named `architecture_name.md` with detailed descriptions, key features, and visual aids.\n",
      "\n",
      "7. **Python Code Implementation (Engineer)**:\n",
      "   - Write Python code for each architecture and save it in a file named `architecture.py`.\n",
      "\n",
      "8. **Testing the Code**:\n",
      "   - Include a testing phase to ensure the implementations work as intended.\n",
      "\n",
      "9. **Review and Feedback (Admin)**:\n",
      "   - Admin reviews markdown files and Python code, providing feedback for revisions.\n",
      "\n",
      "10. **Revisions (Scientist and Engineer)**:\n",
      "    - Make necessary revisions based on admin feedback.\n",
      "\n",
      "11. **Final Approval (Admin)**:\n",
      "    - Admin gives final approval for the project.\n",
      "\n",
      "12. **Version Control**:\n",
      "    - Implement a version control system (like Git) for managing files.\n",
      "\n",
      "13. **Include References**:\n",
      "    - Ensure each architecture's markdown file includes citations and links to original papers.\n",
      "\n",
      "14. **Feedback Loop**:\n",
      "    - Establish a feedback loop for iterative improvements.\n",
      "\n",
      "15. **Timeline**:\n",
      "    - Set a timeline for each phase to ensure timely completion.\n",
      "\n",
      "### Next Steps:\n",
      "- The scientist will begin the research phase with the defined criteria.\n",
      "- The engineer will prepare markdown file templates and set up version control.\n",
      "\n",
      "Regular check-ins will be scheduled to monitor progress and address challenges. Please confirm if you would like to proceed with this updated plan or if there are any further adjustments needed!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "The updated plan is thorough and incorporates valuable suggestions that will enhance the process of gathering and summarizing state-of-the-art video generation architectures. It effectively outlines the responsibilities and steps involved, ensuring a collaborative and organized approach.\n",
      "\n",
      "### Next Steps:\n",
      "1. **Confirmation to Proceed**: Please confirm if you would like to proceed with this updated plan.\n",
      "2. **Research Phase**: Once confirmed, the scientist can begin the research phase based on the defined criteria.\n",
      "3. **Template Preparation**: The engineer can prepare the markdown file templates and set up version control.\n",
      "\n",
      "If there are any additional adjustments or specific timelines you would like to establish, please let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems like there was no specific instruction or feedback in your last message. If you would like to proceed with the updated plan for gathering and summarizing state-of-the-art video generation architectures, please confirm. Alternatively, if you have any questions or further instructions, feel free to share!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It appears that your message is incomplete or may not contain specific instructions. If you have any questions, feedback, or if you would like to proceed with the updated plan, please let me know how I can assist you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there may have been a misunderstanding or a technical issue with the communication. If you have any specific instructions, feedback, or questions regarding the plan for gathering and summarizing state-of-the-art video generation architectures, please feel free to share them. I'm here to assist you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems that there may be a communication issue, as your messages are coming through without additional context or instructions. If you have specific feedback, questions, or if you would like to proceed with the plan regarding the video generation architectures, please provide more details. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there has been a misunderstanding in our communication. If you have specific instructions or feedback regarding the plan for gathering and summarizing state-of-the-art video generation architectures, please let me know. I'm ready to assist you with any tasks or questions you may have!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It appears that your messages are coming through without additional context or instructions. If you have specific feedback, questions, or if you would like to proceed with the plan regarding the video generation architectures, please provide more details. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there has been a miscommunication, as your messages are coming through without additional context. If you have specific instructions or feedback regarding the plan for gathering and summarizing state-of-the-art video generation architectures, please let me know how I can assist you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems that your messages are coming through without additional context or instructions. If you have specific feedback, questions, or if you would like to proceed with the plan regarding the video generation architectures, please provide more details. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there has been a misunderstanding in our communication. If you have specific instructions or feedback regarding the plan for gathering and summarizing state-of-the-art video generation architectures, please let me know. I'm ready to assist you with any tasks or questions you may have!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output_report = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Find 10 state of the art video generation paper architectures (such as VideoGAN, Temporal GAN, Stable diffusion, VideoGPT, Imitation learning Model). Create markdown table summarizing these architectures named video_paper.md as well as markdown for each of the architecture saved as architecture_name.md and python code for each architectures as architecture.py.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Audio Data Preprocessing Steps\n",
       "\n",
       "| Preprocessing Step     | Description                                                                 |\n",
       "|-----------------------|-----------------------------------------------------------------------------|\n",
       "| Normalization         | Adjusts the amplitude of the audio signal to a standard range.             |\n",
       "| Noise Reduction       | Removes unwanted background noise from the audio signal.                   |\n",
       "| Feature Extraction     | Extracts relevant features from the audio signal, such as MFCCs.          |\n",
       "| Resampling            | Changes the sample rate of the audio signal to a different frequency.      |\n",
       "| Trimming/Silence Removal | Cuts out silent parts of the audio signal to reduce file size and improve processing. |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown('paper/2024_audio_processing.md')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
