{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Basic Components**\n",
    "- **1. Model** - Abstractions over LLM APIs\n",
    "- **2.Prompt Templates** - abstraction over the prompt sent to the model\n",
    "- **3.Output Parser** - abstraction to translate raw output from the model to workable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain--core\n",
      "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.11-cp39-cp39-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.6-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
      "  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain--core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain--core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain--core) (4.12.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl.metadata (71 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain--core)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp39-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading jiter-0.8.2-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\saxen\\anaconda3\\envs\\langchain\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "Downloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
      "Downloading aiohttp-3.11.11-cp39-cp39-win_amd64.whl (442 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Downloading langsmith-0.2.6-py3-none-any.whl (325 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.1/15.8 MB 15.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.2/15.8 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 14.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp39-cp39-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.8/884.8 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp39-cp39-win_amd64.whl (298 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.8.2-cp39-cp39-win_amd64.whl (207 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.12-cp39-none-win_amd64.whl (134 kB)\n",
      "Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl (90 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, sniffio, regex, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, jiter, idna, h11, greenlet, frozenlist, distro, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, httpx, aiohttp, openai, langsmith, langchain--core, langchain-text-splitters, langchain-openai, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.7.0 async-timeout-4.0.3 attrs-24.3.0 certifi-2024.12.14 charset-normalizer-3.4.1 distro-1.9.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.13 langchain--core-0.3.28 langchain-openai-0.2.14 langchain-text-splitters-0.3.4 langsmith-0.2.6 multidict-6.1.0 numpy-1.26.4 openai-1.58.1 orjson-3.10.12 propcache-0.2.1 pydantic-2.10.4 pydantic-core-2.27.2 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 urllib3-2.3.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-openai langchain--core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "def load_api_key(yml_file):\n",
    "    with open(yml_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)  # Safely load the YAML file\n",
    "        return config.get('openai_key')  # Retrieve the 'api_key'\n",
    "\n",
    "# Usage\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] =load_api_key('chatgpt_api_credentials.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Certainly! Langchain is a framework designed to facilitate the development of applications using language models. Here are some of its basic components:\\n\\n- **Chains**: Sequences of operations that can be linked together to process input and produce output. Chains can be simple (one model) or complex (multiple models and tools).\\n\\n- **Agents**: These are components that can interact with external APIs or tools based on the instructions provided. Agents decide which actions to take in response to user input.\\n\\n- **Prompts**: Templates or structures used to format input for language models. They help in guiding the model to produce the desired output.\\n\\n- **Memory**: A component that allows the application to remember past interactions or context, enabling more coherent and personalized responses.\\n\\n- **Document Loaders**: Tools that help in retrieving and loading documents from various sources (like PDFs, web pages, etc.) for processing and querying.\\n\\n- **Text Splitters**: Utilities that divide documents into smaller chunks, making it easier to work with large texts and improving the efficiency of processing.\\n\\n- **Retrievers**: Components that help in fetching relevant documents or information from a database or knowledge base based on a query.\\n\\n- **Vector Stores**: Systems designed to store and retrieve embeddings (vector representations of text) for efficient similarity searches.\\n\\n- **Tools**: Various utilities or external services that can be integrated into applications, enabling additional functionalities (e.g., calculators, web search).\\n\\n- **Callbacks**: Mechanisms that allow you to hook into the execution process of chains or agents, enabling logging, monitoring, or other custom behaviors.\\n\\nThese components can be combined and customized to create powerful applications that leverage language models for a wide range of use cases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 347, 'prompt_tokens': 25, 'total_tokens': 372, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-306db57b-a5da-4219-8f5b-4d361f9e8309-0', usage_metadata={'input_tokens': 25, 'output_tokens': 347, 'total_tokens': 372, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm =  ChatOpenAI(model='gpt-4o-mini')\n",
    "llm.invoke('Hi I am learning Langchain? Tell me about some of its basic components in bullet points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Give me five examples of:basic components of Langchain?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt =ChatPromptTemplate.from_template('Give me five examples of:{things_to_give_examples}')\n",
    "prompt.format(\n",
    " things_to_give_examples='basic components of Langchain?'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a framework designed to facilitate the development of applications using language models. Here are five key components of LangChain:\\n\\n1. **Chains**: These are sequences of operations that can be executed in a specific order. Chains can combine multiple steps, such as querying a language model, processing the output, and performing additional actions based on that output.\\n\\n2. **Agents**: Agents are components that can take actions based on user queries or inputs. They can use a language model to determine the best course of action and can make decisions about which tools or functions to call.\\n\\n3. **Tools**: Tools are external functions or APIs that can be called by agents or chains to perform specific tasks. For example, tools may include web scraping functions, database queries, or API calls to retrieve information.\\n\\n4. **Memory**: Memory components allow applications to maintain state across interactions. This means that the application can remember previous interactions with a user, which can improve the relevance and context of responses.\\n\\n5. **Document Loaders**: Document loaders are responsible for ingesting and processing documents from various sources. They can support different file formats and data sources, making it easier to work with unstructured data in applications.\\n\\nThese components work together to create powerful applications that leverage the capabilities of language models.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 261, 'prompt_tokens': 17, 'total_tokens': 278, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-4c59802a-fe30-462e-9dd0-db175d5d4d77-0', usage_metadata={'input_tokens': 17, 'output_tokens': 261, 'total_tokens': 278, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_chain = prompt | llm\n",
    "\n",
    "basic_chain.invoke({'things_to_give_examples': 'components of Langchain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example chain 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "complete_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here are five creative animal names:\\n\\n1. **Whiskerfluff** - A playful name for a fluffy cat or rabbit.\\n2. **Bumblebark** - A whimsical name for a friendly dog with a bouncy personality.\\n3. **Finsanity** - A fun name for an energetic fish that darts around its tank.\\n4. **Pawtastic** - A catchy name for a pet that’s always getting into fun adventures.\\n5. **Snugglebeak** - A cozy name for a cuddly bird that loves to perch on your shoulder.\\n\\nFeel free to use or modify these names as you see fit!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_chain.invoke({'things_to_give_examples':'creative animal names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
